## convert GPSPoints to a table for manipulation
GPSPoints <- cbind(GPSPoints, sf::st_coordinates(GPSPoints)) %>%
st_zm %>% as.data.frame()
## this solves issue where geom is named 'geometry' other times 'geom'
if("geom" %in% names(GPSPoints)) {
GPSPoints <- GPSPoints %>%  dplyr::rename(geometry = geom)}
## Define the Line Start and End Coordinates
## Add XY coordinates as
lines <- GPSPoints %>%
dplyr::mutate(Xend = lead(X),
Yend = lead(Y)) %>%  # collect the coordinates of the next point
dplyr::filter(!is.na(Yend)) #%>% # drops the last row (start point with no end)
# dplyr::select(-geometry)
## Use data.table with sf to create the line geometry
dt <- data.table::as.data.table(lines)
sf <- dt[,
{
geometry <- sf::st_linestring(x = matrix(c(X, Xend, Y, Yend), ncol = 2))
geometry <- sf::st_sfc(geometry)
geometry <- sf::st_sf(geometry = geometry)
}
, by = ID
]
## Replace the geometry
lines$geometry <- sf$geometry
## Declare as a simple feature
lines <- st_sf(lines)
st_crs(lines) <- PROJ
## Need to remove excess lines -- currently there are lines that run between the plots
lines$within <- as.logical(st_within(lines, planT))
lines <- lines[!is.na(lines$within == TRUE),]  ## removes lines not contained in Transect area
## There are a few invalid geometries
lines$valid <- as.logical(st_is_valid(lines))
# lines <- lines[lines$valid == TRUE,]  ## removes lines not contained in Transect area
# lines <- lines %>% dplyr::select(TID, id, name, time, SiteSeries:Confidence)
return(lines)
} else {
## Begin transect method ----------------------------------------------------
## ADD MC's code here
if (method == "tracklog") {
print("Not built yet")
print("Copy in MC's code")
}
}
}
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
library(pemgeneratr)
?predict_landscape
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
?pemgeneratr::cov_dtm()
i <- 1
#' Solution is currently a hack.  See `load tile area`.
#'
#' @param model Location of a `mlr` model object (i.e. path to it.)
#' @param cov   A list of raster files.  These will be loaded as a `stars` object
#' @param tilesize Specify the number of pixels in the `x` and `y` directions for the tiles to be generated.  If your computer is mememory limited use a smaller tile (e.g. 500).
#' @param outDir directory for the output file.
#' @keywords predict, landscape
#' @export
#' @examples
#' ### Testing
cov <- list.files("e:/tmpGIS/PEM_cvs/", pattern = "*.tif",full.names = TRUE)
cov <- cov[-(grep(cov, pattern = "xml"))]
#'
# predict_landscape(,
model = "e:/tmp/model_gen_test/model.rds"#,
cov = cov#,
tilesize = 1000#,
outDir = "e:/tmp/predict_landscape_bug"
## libraries  -----
library(dplyr)
library(mlr)
## Adjust names
## This will be used in the loop to rename stars object
n <- basename(cov)
n <- gsub(".tif", "", n)
## Load the model -----
mod <- readRDS(model)
dir.create(outDir) ## create output dir -----------
## create tiles ---------------
tiles <- pemgeneratr::tile_index(cov[1], tilesize)
t <- tiles[i,]  ## get tile
print(paste("working on ", i, "of", nrow(tiles)))
print("...")
## * load tile area---------
print("... loading new data (from rasters)...")
r <- stars::read_stars(cov,
RasterIO = list(nXOff  = t$offset.x[1]+1, ## hack -- stars and tile_maker issue??
nYOff  = t$offset.y[1]+1,
nXSize = t$region.dim.x[1],
nYSize = t$region.dim.y[1]))
## * update names ---------
names(r) <- n
## * convert tile to dataframe ---------
rsf <- sf::st_as_sf(r, as_points = TRUE)
print(setdiff(mod$features, n))
print(setdiff(n, mod$features))
print(setdiff(n, mod$features))
length(setdiff(n, mod$features) > 0
)
length(setdiff(n, mod$features) > 0 )
## drop rasters if not included in model
if (length(setdiff(n, mod$features) > 0 )) {
print("The following rasters are removed as they were not included in the model")
print(setdiff(n, mod$features))
}
drop_layers <- setdiff(n, mod$features)
drop_layers
basename((cov))
drop_layers <- paste0(setdiff(n, mod$features), "*.tif"
}
dir.create(outDir) ## create output dir -----------
## create tiles ---------------
tiles <- pemgeneratr::tile_index(cov[1], tilesize)
## alternate -- outside of pemgeneratr
# source(here::here('_functions', 'tile_index.R'))
# tiles <- tile_index(cov[1], tilesize)
## begin loop through tiles -----
## set up progress messaging
a <- 0 ## running total of area complete
ta <- sum(as.numeric(sf::st_area(tiles)))
for (i in 1:nrow(tiles)) {    ## testing first 2 tiles       ##nrow(tiles)) {
t <- tiles[i,]  ## get tile
print(paste("working on ", i, "of", nrow(tiles)))
print("...")
## * load tile area---------
print("... loading new data (from rasters)...")
r <- stars::read_stars(cov,
RasterIO = list(nXOff  = t$offset.x[1]+1, ## hack -- stars and tile_maker issue??
nYOff  = t$offset.y[1]+1,
nXSize = t$region.dim.x[1],
nYSize = t$region.dim.y[1]))
## * update names ---------
names(r) <- n
## * convert tile to dataframe ---------
rsf <- sf::st_as_sf(r, as_points = TRUE)
# rsf <- na.omit(rsf)  ## na.omit caused issues
## * Test if tile is empty -------------
na_table <- as.data.frame(sapply(rsf, function(x) all(is.na(x))))
## * determine na counts -- this will be used to restore NA values if tile is run.
na_table$count <- as.data.frame(sapply(rsf, function(x) sum(is.na(x))))[,1]
## If any attribute is empty skip the tile
if(any(na_table[,1] == TRUE)) {
print("some variables with all NA values, skipping tile")
} else{
## * Test if tile is empty -- original version
# naTest <- as.data.frame(rsf[,1])
# naTest <- naTest[,1]
# if (sum(!is.na(naTest)) == 0) { ## if all the values in the tile are NA skip to next tile.
#   print("... Empty tile moving to next...")
# } else {
## * predict ---------
## * * Managing NA values ----------------
## When some of the values are NA change them to zero
## * Identify the attribute with the highest number of NA values.
na_max <- na_table[na_table$count ==  max(na_table$count),]
na_max <- row.names(na_max[1,]) ## if multiple attributes -- take the first
## make a copy of the attribute with the highest number of na values
rsf_bk <- rsf[,na_max]  ## -- this will be used to restore NA values
rsf[is.na(rsf)] <- 0 ## convert NA to zero as the predict function cannot handle NA
print("... modelling outcomes (predicting)...")
pred <- predict(mod, newdata = rsf)
## Restore NA values
pred_dat <- pred$data ## predicted values extracted
pred_dat[is.na(rsf_bk[,1]), 1:length(pred_dat)] <- NA ## if originally NA restore NA
pred$data <- pred_dat ## values restored to pred -- allows for cbind without issue.
## * geo-link predicted values ---------
r_out <- cbind(rsf, pred)
## layers to keep (i.e. newly predicted layers)
keep <- setdiff(names(r_out),
names(r))
keep <- keep[-length(keep)] ## drops the last entry (geometry field, not a name)
r_out <- r_out %>% dplyr::select(keep)
## Save the names of the model response -----
## The levels are in the multiclass 'response'
wkey <- 0
if (wkey == 0)  {
respNames <- levels(r_out$response) ## this becomes the dictionary to describe the raster values
write.csv(respNames, paste(outDir, "response_names.csv",
sep = "/"),
row.names = TRUE)
wkey <- 1 ## Change this value so this small is statement does not execute again.
}
## change the text values to numeric values.
r_out$response <- as.numeric(r_out$response)
## Set up subdirectories for rastertile outputs
print("... exporting raster tiles...")
for (k in keep) {
dir.create(paste(outDir, k, sep = "/"))
}
## * save tile (each pred item saved) ---------
for (j in 1:length(keep)) {
# j <- 2  ## testing
out <- stars::st_rasterize(r_out[j],
template = r[1])
stars::write_stars(out,
paste0(outDir,"/",
keep[j], "/",             #sub-directoy
keep[j], "_", i, ".tif")) #tile name
}
## * report progress -----
a <- a + as.numeric(sf::st_area(t))
print(paste(round(a/ta*100,1), "% complete"))
print("") ## blank line
} ## end if statement -- for when tile is empty
} ## END LOOP -------------
print("All predicted tiles generated")
## Mosaic Tiles ---------------
print("Generating raster mosaics")
for (k in keep) {
# get list of tiles
r_tiles <- list.files(paste(outDir, k, sep = "/"),
pattern = ".tif",
full.names = TRUE)
# remove pot. xml files
r_tiles <- r_tiles[-(grep(r_tiles, pattern = "xml"))] ## drop any associated xml files
## mosaic
gdalUtils::mosaic_rasters(gdalfile = r_tiles, ## list of rasters to mosaic
dst_dataset = paste0(outDir, "/", k, ".tif"),  #output: dir and filename
output_Raster = TRUE) ## saves the raster (not just a virtual raster)
}
} ### end positive if statment ----------
} ### end function
paste0(setdiff(n, mod$features), "*.tif")
paste0(setdiff(n, mod$features), ".tif")
cov
cov2 <- cov[, basename(cov) %in% drop_layers]
cov2 <- cov[, -c(basename(cov) %in% drop_layers)]
basename(cov) %in% drop_layers
basename(cov)
cov2 <- basename(cov)
cov2 %in% drop_layers
str(cov2)
str(drop_layers)
cov2 %in% any(drop_layers)
?setdiff
is.element(cov2, drop_layers)
is.element(drop_layers, cov2)
cov2
drop_layers
drop_layers <- paste0(setdiff(n, mod$features), ".tif")
is.element(drop_layers, cov2)
is.element(drop_layers, cov2)
is.element(cov2, drop_layers)
cov2 <- cov[, -c(cov %in% drop_layers)]
cov2 <- cov[, -is.element(cov, drop_layers)]
cov2 <- cov[-c(cov %in% drop_layers)]
cov2 <- setdiff(cov, drop_layers)
setdiff(cov, drop_layers)
cov2 <- setdiff(basename(cov), drop_layers)
#' Solution is currently a hack.  See `load tile area`.
#'
#' @param model Location of a `mlr` model object (i.e. path to it.)
#' @param cov   A list of raster files.  These will be loaded as a `stars` object
#' @param tilesize Specify the number of pixels in the `x` and `y` directions for the tiles to be generated.  If your computer is mememory limited use a smaller tile (e.g. 500).
#' @param outDir directory for the output file.
#' @keywords predict, landscape
#' @export
#' @examples
#' ### Testing
cov <- list.files("e:/tmpGIS/PEM_cvs/", pattern = "*.tif",full.names = TRUE)
cov <- cov[-(grep(cov, pattern = "xml"))]
#'
# predict_landscape(,
model = "e:/tmp/model_gen_test/model.rds"#,
cov = cov#,
tilesize = 1000#,
outDir = "e:/tmp/predict_landscape_bug"
## libraries  -----
library(dplyr)
library(mlr)
## Adjust names
## This will be used in the loop to rename stars object
n <- basename(cov)
n <- gsub(".tif", "", n)
## Load the model -----
mod <- readRDS(model)
## drop rasters if not included in model
if (length(setdiff(n, mod$features) > 0 )) {
print("The following rasters are removed as they were not included in the model:")
print(setdiff(n, mod$features))
## drop layers not used
drop_layers <- paste0(setdiff(n, mod$features), ".tif")
cov2 <- setdiff(basename(cov), drop_layers)
}
cov <- setdiff(basename(cov), drop_layers)
dir.create(outDir) ## create output dir -----------
## create tiles ---------------
tiles <- pemgeneratr::tile_index(cov[1], tilesize)
## create tiles ---------------
tiles <- pemgeneratr::tile_index(cov[1], tilesize)
cov
#' Solution is currently a hack.  See `load tile area`.
#'
#' @param model Location of a `mlr` model object (i.e. path to it.)
#' @param cov   A list of raster files.  These will be loaded as a `stars` object
#' @param tilesize Specify the number of pixels in the `x` and `y` directions for the tiles to be generated.  If your computer is mememory limited use a smaller tile (e.g. 500).
#' @param outDir directory for the output file.
#' @keywords predict, landscape
#' @export
#' @examples
#' ### Testing
cov <- list.files("e:/tmpGIS/PEM_cvs/", pattern = "*.tif",full.names = TRUE)
cov <- cov[-(grep(cov, pattern = "xml"))]
#'
# predict_landscape(,
model = "e:/tmp/model_gen_test/model.rds"#,
cov = cov#,
tilesize = 1000#,
outDir = "e:/tmp/predict_landscape_bug"
## libraries  -----
library(dplyr)
library(mlr)
## Adjust names
## This will be used in the loop to rename stars object
n <- basename(cov)
n <- gsub(".tif", "", n)
## Load the model -----
mod <- readRDS(model)
cov2 <- cov[setdiff(basename(cov), drop_layers)]
## drop layers not used
drop_layers <- paste0(setdiff(n, mod$features), ".tif")
cov2 <- cov[setdiff(basename(cov), drop_layers)]
cov <- cov[setdiff(basename(cov), drop_layers)]
cov
#' Solution is currently a hack.  See `load tile area`.
#'
#' @param model Location of a `mlr` model object (i.e. path to it.)
#' @param cov   A list of raster files.  These will be loaded as a `stars` object
#' @param tilesize Specify the number of pixels in the `x` and `y` directions for the tiles to be generated.  If your computer is mememory limited use a smaller tile (e.g. 500).
#' @param outDir directory for the output file.
#' @keywords predict, landscape
#' @export
#' @examples
#' ### Testing
cov <- list.files("e:/tmpGIS/PEM_cvs/", pattern = "*.tif",full.names = TRUE)
cov <- cov[-(grep(cov, pattern = "xml"))]
#'
# predict_landscape(,
model = "e:/tmp/model_gen_test/model.rds"#,
tilesize = 1000#,
outDir = "e:/tmp/predict_landscape_bug"
print("The following rasters are removed as they were not included in the model:")
print(setdiff(n, mod$features))
## drop layers not used
drop_layers <- paste0(setdiff(n, mod$features), ".tif")
cov2 <- cov[ basename(cov) %in% drop_layers)]
cov2 <- cov[ basename(cov) %in% drop_layers]
cov2 <- cov[ -(basename(cov) %in% drop_layers)]
## drop layers not used
drop_layers <- paste0(setdiff(n, mod$features), ".tif")
cov2 <- cov[ -(basename(cov) %in% drop_layers)]
cov2 <- cov[is.element(basename(cov), drop_layers)]
cov2 <- cov[is.element(drop_layers, basename(cov))]
keep_layers <- setdiff(drop_layers, basename(cov))
## drop layers not used
drop_layers <- paste0(setdiff(n, mod$features), ".tif")
keep_layers <- setdiff(drop_layers, basename(cov))
setdiff(drop_layers, basename(cov))
drop_layers
basename(cov)
#' Solution is currently a hack.  See `load tile area`.
#'
#' @param model Location of a `mlr` model object (i.e. path to it.)
#' @param cov   A list of raster files.  These will be loaded as a `stars` object
#' @param tilesize Specify the number of pixels in the `x` and `y` directions for the tiles to be generated.  If your computer is mememory limited use a smaller tile (e.g. 500).
#' @param outDir directory for the output file.
#' @keywords predict, landscape
#' @export
#' @examples
#' ### Testing
cov <- list.files("e:/tmpGIS/PEM_cvs/", pattern = "*.tif",full.names = TRUE)
cov <- cov[-(grep(cov, pattern = "xml"))]
## Adjust names
## This will be used in the loop to rename stars object
n <- basename(cov)
n <- gsub(".tif", "", n)
## Load the model -----
mod <- readRDS(model)
## drop layers not used
drop_layers <- paste0(setdiff(n, mod$features), ".tif")
keep_layers <- paste0(setdiff(mod$features, n), ".tif")
## drop layers not used
drop_layers <- paste0(setdiff(n, mod$features), ".tif")
keep_layers <- basename(cov)[-drop_layers]
keep_layers <- subset(cov, !(basename(cov) %in% drop_layers) )
keep_layers
#' Solution is currently a hack.  See `load tile area`.
#'
#' @param model Location of a `mlr` model object (i.e. path to it.)
#' @param cov   A list of raster files.  These will be loaded as a `stars` object
#' @param tilesize Specify the number of pixels in the `x` and `y` directions for the tiles to be generated.  If your computer is mememory limited use a smaller tile (e.g. 500).
#' @param outDir directory for the output file.
#' @keywords predict, landscape
#' @export
#' @examples
#' ### Testing
cov <- list.files("e:/tmpGIS/PEM_cvs/", pattern = "*.tif",full.names = TRUE)
cov <- cov[-(grep(cov, pattern = "xml"))]
#'
# predict_landscape(,
model = "e:/tmp/model_gen_test/model.rds"#,
cov = cov#,
tilesize = 1000#,
outDir = "e:/tmp/predict_landscape_bug"
## Adjust names
## This will be used in the loop to rename stars object
n <- basename(cov)
n <- gsub(".tif", "", n)
## Load the model -----
mod <- readRDS(model)
## drop rasters if not included in model
if (length(setdiff(n, mod$features) > 0 )) {
print("The following rasters are removed as they were not included in the model:")
print(setdiff(n, mod$features))
## drop layers not used
drop_layers <- paste0(setdiff(n, mod$features), ".tif")
cov <- subset(cov, !(basename(cov) %in% drop_layers) )
}
## create tiles ---------------
tiles <- pemgeneratr::tile_index(cov[1], tilesize)
i <-1
t <- tiles[i,]  ## get tile
print(paste("working on ", i, "of", nrow(tiles)))
print("...")
## * load tile area---------
print("... loading new data (from rasters)...")
r <- stars::read_stars(cov,
RasterIO = list(nXOff  = t$offset.x[1]+1, ## hack -- stars and tile_maker issue??
nYOff  = t$offset.y[1]+1,
nXSize = t$region.dim.x[1],
nYSize = t$region.dim.y[1]))
## * update names ---------
names(r) <- n
n <- basename(cov)
n <- basename(cov) ; n <- gsub(".tif", "", n)
n <- basename(cov) ; n <- gsub(".tif", "", n)  ## fix n
## * update names ---------
names(r) <- n
## * convert tile to dataframe ---------
rsf <- sf::st_as_sf(r, as_points = TRUE)
## * Test if tile is empty -------------
na_table <- as.data.frame(sapply(rsf, function(x) all(is.na(x))))
## * determine na counts -- this will be used to restore NA values if tile is run.
na_table$count <- as.data.frame(sapply(rsf, function(x) sum(is.na(x))))[,1]
any(na_table[,1] == TRUE)
## * * Managing NA values ----------------
## When some of the values are NA change them to zero
## * Identify the attribute with the highest number of NA values.
na_max <- na_table[na_table$count ==  max(na_table$count),]
na_max <- row.names(na_max[1,]) ## if multiple attributes -- take the first
na_max
na_table
na_max <- row.names(na_max[1,]) ## if multiple attributes -- take the first
## make a copy of the attribute with the highest number of na values
rsf_bk <- rsf[,na_max]  ## -- this will be used to restore NA values
rsf[is.na(rsf)] <- 0 ## convert NA to zero as the predict function cannot handle NA
print("... modelling outcomes (predicting)...")
pred <- predict(mod, newdata = rsf)
## Restore NA values
pred_dat <- pred$data ## predicted values extracted
pred_dat[is.na(rsf_bk[,1]), 1:length(pred_dat)] <- NA ## if originally NA restore NA
pred$data <- pred_dat ## values restored to pred -- allows for cbind without issue.
## * geo-link predicted values ---------
r_out <- cbind(rsf, pred)
## layers to keep (i.e. newly predicted layers)
keep <- setdiff(names(r_out),
names(r))
keep <- keep[-length(keep)] ## drops the last entry (geometry field, not a name)
r_out <- r_out %>% dplyr::select(keep)
## Save the names of the model response -----
## The levels are in the multiclass 'response'
wkey <- 0
if (wkey == 0)  {
respNames <- levels(r_out$response) ## this becomes the dictionary to describe the raster values
write.csv(respNames, paste(outDir, "response_names.csv",
sep = "/"),
row.names = TRUE)
wkey <- 1 ## Change this value so this small is statement does not execute again.
}
## change the text values to numeric values.
r_out$response <- as.numeric(r_out$response)
## Set up subdirectories for rastertile outputs
print("... exporting raster tiles...")
for (k in keep) {
dir.create(paste(outDir, k, sep = "/"))
}
## * save tile (each pred item saved) ---------
for (j in 1:length(keep)) {
# j <- 2  ## testing
out <- stars::st_rasterize(r_out[j],
template = r[1])
stars::write_stars(out,
paste0(outDir,"/",
keep[j], "/",             #sub-directoy
keep[j], "_", i, ".tif")) #tile name
}
r_avenza <- function(shp, gpx) {
r_avenza <- function(shp, gpx) {
r_avenza <- function(shp, gpx) {
library(magrittr)
gpx <- as.data.frame(dplyr::select(time)) ## Grab timestamp from gpx data
## join data and return relavent columns
shp <- dplyr::bind_cols() %>% arrange(time) %>% ## bind
mutate(id = row_number()) %>%
dplyr::select(id, name, time, Photos, desc)
return(shp)
}
shp <- st_read("./39_WBear_aerial_pem/Layer.shp", quiet = TRUE)
