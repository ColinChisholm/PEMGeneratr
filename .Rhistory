outDir = "./predicted") {
## libraries  -----
library(dplyr)
library(mlr)
## Adjust names
## This will be used in the loop to rename stars object
n <- basename(cov)
n <- gsub(".tif", "", n)
## Load the model -----
mod <- readRDS(model)
## Error handle -- model vs. cov -----------
## If names in model features are found in the cov list continue.
## ELSE exit with message
if (length(setdiff(mod$features, n)) != 0) { ## tests if all model features are found in the cov list
## On model vs. cov error ---------------
print("Name mis-match between the model features and the names of the rasters.")
print("The following raster co-variates are not found in the model features list:")
print(setdiff(mod$features, n))
}
redict_landscape <- function(model, cov,tilesize = 500,
outDir = "./predicted") {
## libraries  -----
library(dplyr)
library(mlr)
## Adjust names
## This will be used in the loop to rename stars object
n <- basename(cov)
n <- gsub(".tif", "", n)
## Load the model -----
mod <- readRDS(model)
## Error handle -- model vs. cov -----------
## If names in model features are found in the cov list continue.
## ELSE exit with message
if (length(setdiff(mod$features, n)) != 0) { ## tests if all model features are found in the cov list
## On model vs. cov error ---------------
print("Name mis-match between the model features and the names of the rasters.")
print("The following raster co-variates are not found in the model features list:")
print(setdiff(mod$features, n))
} else {
dir.create(outDir) ## create output dir -----------
## create tiles ---------------
tiles <- pemgeneratr::tile_index(cov[1], tilesize)
## alternate -- outside of pemgeneratr
# source("./R/tile_index.R")  ## load the tile index function
# tiles <- tile_index(cov[1], tilesize)
## begin loop through tiles -----
## set up progress messaging
a <- 0 ## running total of area complete
ta <- sum(as.numeric(sf::st_area(tiles)))
for (i in 1:2) {    ## testing first 2 tiles       ##nrow(tiles)) {
t <- tiles[i,]  ## get tile
print(paste("working on ", i, "of", nrow(tiles)))
print("...")
## * load tile area---------
print("... loading new data (from rasters)...")
r <- stars::read_stars(cov,
RasterIO = list(nXOff  = t$offset.x[1]+1, ## hack -- stars and tile_maker issue??
nYOff  = t$offset.y[1]+1,
nXSize = t$region.dim.x[1],
nYSize = t$region.dim.y[1]))
## * update names ---------
names(r) <- n
## * convert tile to dataframe ---------
rsf <- sf::st_as_sf(r, as_points = TRUE)
rsf <- na.omit(rsf)
## * predict ---------
print("... modelling outcomes (predicting)...")
pred <- predict(mod, newdata = rsf)
## * geo-link predicted values ---------
r_out <- cbind(rsf, pred)
## layers to keep (i.e. newly predicted layers)
keep <- setdiff(names(r_out),
names(r))
keep <- keep[-length(keep)] ## drops the last entry (geometry field, not a name)
r_out <- r_out %>% dplyr::select(keep)
## Set up subdirectories for rastertile outputs
print("... exporting raster tiles...")
for (k in keep) {
dir.create(paste(outDir, k, sep = "/"))
}
## * save tile (each pred item saved) ---------
for (j in 1:length(keep)) {
# j <- 2  ## testing
out <- stars::st_rasterize(r_out[j],
template = r[1])
stars::write_stars(out,
paste0(outDir,"/",
keep[j], "/",             #sub-directoy
keep[j], "_", i, ".tif")) #tile name
}
## * report progress -----
a <- a + as.numeric(sf::st_area(t))
print(paste(round(a/ta*100,1), "% of", round(as.numeric(ta)/ 10000, 1), "hectares complete"))
print("") ## blank line
} ## END LOOP -------------
## Save the names of the model response -----
## The levels are in the multiclass
respNames <- levels(r_out$response) ## this becomes the dictionary to describe the raster values
write.csv(respNames, paste(outDir, "response_names.csv",
sep = "/"),
row.names = FALSE)
## Mosaic Tiles ---------------
for (k in keep) {
# get list of tiles
r_tiles <- list.files(paste(outDir, k, sep = "/"),
pattern = ".tif",
full.names = TRUE)
## mosaic
gdalUtils::mosaic_rasters(gdalfile = r_tiles, ## list of rasters to mosaic
dst_dataset = paste0(outDir, "/", k, ".tif"),  #output: dir and filename
output_Raster = TRUE) ## saves the raster (not just a virtual raster)
}
} ### end positive if statment ----------
} ### end function
rm(redict_landscape())
rm(redict_landscape
)
predict_landscape <- function(model, cov,tilesize = 500,
outDir = "./predicted") {
## libraries  -----
library(dplyr)
library(mlr)
## Adjust names
## This will be used in the loop to rename stars object
n <- basename(cov)
n <- gsub(".tif", "", n)
## Load the model -----
mod <- readRDS(model)
## Error handle -- model vs. cov -----------
## If names in model features are found in the cov list continue.
## ELSE exit with message
if (length(setdiff(mod$features, n)) != 0) { ## tests if all model features are found in the cov list
## On model vs. cov error ---------------
print("Name mis-match between the model features and the names of the rasters.")
print("The following raster co-variates are not found in the model features list:")
print(setdiff(mod$features, n))
} else {
dir.create(outDir) ## create output dir -----------
## create tiles ---------------
tiles <- pemgeneratr::tile_index(cov[1], tilesize)
## alternate -- outside of pemgeneratr
# source("./R/tile_index.R")  ## load the tile index function
# tiles <- tile_index(cov[1], tilesize)
## begin loop through tiles -----
## set up progress messaging
a <- 0 ## running total of area complete
ta <- sum(as.numeric(sf::st_area(tiles)))
for (i in 1:2) {    ## testing first 2 tiles       ##nrow(tiles)) {
t <- tiles[i,]  ## get tile
print(paste("working on ", i, "of", nrow(tiles)))
print("...")
## * load tile area---------
print("... loading new data (from rasters)...")
r <- stars::read_stars(cov,
RasterIO = list(nXOff  = t$offset.x[1]+1, ## hack -- stars and tile_maker issue??
nYOff  = t$offset.y[1]+1,
nXSize = t$region.dim.x[1],
nYSize = t$region.dim.y[1]))
## * update names ---------
names(r) <- n
## * convert tile to dataframe ---------
rsf <- sf::st_as_sf(r, as_points = TRUE)
rsf <- na.omit(rsf)
## * predict ---------
print("... modelling outcomes (predicting)...")
pred <- predict(mod, newdata = rsf)
## * geo-link predicted values ---------
r_out <- cbind(rsf, pred)
## layers to keep (i.e. newly predicted layers)
keep <- setdiff(names(r_out),
names(r))
keep <- keep[-length(keep)] ## drops the last entry (geometry field, not a name)
r_out <- r_out %>% dplyr::select(keep)
## Set up subdirectories for rastertile outputs
print("... exporting raster tiles...")
for (k in keep) {
dir.create(paste(outDir, k, sep = "/"))
}
## * save tile (each pred item saved) ---------
for (j in 1:length(keep)) {
# j <- 2  ## testing
out <- stars::st_rasterize(r_out[j],
template = r[1])
stars::write_stars(out,
paste0(outDir,"/",
keep[j], "/",             #sub-directoy
keep[j], "_", i, ".tif")) #tile name
}
## * report progress -----
a <- a + as.numeric(sf::st_area(t))
print(paste(round(a/ta*100,1), "% of", round(as.numeric(ta)/ 10000, 1), "hectares complete"))
print("") ## blank line
} ## END LOOP -------------
## Save the names of the model response -----
## The levels are in the multiclass
respNames <- levels(r_out$response) ## this becomes the dictionary to describe the raster values
write.csv(respNames, paste(outDir, "response_names.csv",
sep = "/"),
row.names = FALSE)
## Mosaic Tiles ---------------
for (k in keep) {
# get list of tiles
r_tiles <- list.files(paste(outDir, k, sep = "/"),
pattern = ".tif",
full.names = TRUE)
## mosaic
gdalUtils::mosaic_rasters(gdalfile = r_tiles, ## list of rasters to mosaic
dst_dataset = paste0(outDir, "/", k, ".tif"),  #output: dir and filename
output_Raster = TRUE) ## saves the raster (not just a virtual raster)
}
} ### end positive if statment ----------
} ### end function
predict_landscape(model = "e:/tmp/model_gen_test/model.rds",
cov = cov,
tilesize = 1000,
outDir = "e:/tmp/predict_landscape")
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
pemgeneratr::model_gen()
?pemgeneratr::model_gen()
|pemgeneratr::predict_landscape()
?pemgeneratr::predict_landscape()
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
# Chunk 2
# install.packages("mlr", dependencies = TRUE)
library(mlr)
library(tidyverse)
## Load the data
modDat <- params$traindat
target <- params$target
## define output directory
outDir <- params$outDir
## define output directory
outDir <- "e:/tmp/mlr_5m_200323/"
table(modDat[,target])
modDat
## Load the data
modDat <- st_read("../../ALRF_PEMv2/spatialData/SamplePoints_with_rast_values.gpkg", quiet = TRUE) %>%
dplyr::select(SiteSeries, aspect_025:VerticalDistance_25m) %>%
dplyr::select(-c(Vertical_distance_025:VerticalDistance_25m,   ## remove problematic covariates
overland_flow_025:OverlandFlowDistance_25m))
## Load the data
modDat <- sf::st_read("../../ALRF_PEMv2/spatialData/SamplePoints_with_rast_values.gpkg", quiet = TRUE) %>%
dplyr::select(SiteSeries, aspect_025:VerticalDistance_25m) %>%
dplyr::select(-c(Vertical_distance_025:VerticalDistance_25m,   ## remove problematic covariates
overland_flow_025:OverlandFlowDistance_25m))
## Load the data
modDat <- sf::st_read("e:/workspace/2020/PEM/ALRF_PEMv2/spatialData/SamplePoints_with_rast_values.gpkg",
quiet = TRUE) %>%
dplyr::select(SiteSeries, aspect_025:VerticalDistance_25m) %>%
dplyr::select(-c(Vertical_distance_025:VerticalDistance_25m,   ## remove problematic covariates
overland_flow_025:OverlandFlowDistance_25m))
target <- "SiteSeries"
## define output directory
outDir <- "e:/tmp/mlr_5m_200323/"
table(modDat[,target])
modDat
table(modDat[, target])
table(modDat$[target])
modDat %>% dplyr::select(target)
modDat %>% dplyr::select(target) %>% table(.)
modDat %>% as.data.frame() %>% dplyr::select(target)
modDat %>% as.data.frame() %>% dplyr::select(target) %>% table(.)
## use or create a random number seed -- this can be used to repeat results in future.
if (!is.na(rseed)) {
set.seed(rseed)
print(paste("Random number generator seed set to:", rseed))
} else {
rseed <- as.integer(Sys.time())
print(paste("Random number generator seed set to:", rseed))
}
rseed <- NA
## use or create a random number seed -- this can be used to repeat results in future.
if (!is.na(rseed)) {
set.seed(rseed)
print(paste("Random number generator seed set to:", rseed))
} else {
rseed <- as.integer(Sys.time())
print(paste("Random number generator seed set to:", rseed))
}
## Create task
tsk <- makeClassifTask(data = modDat, target = "SiteSeries")
## Define Learner
lrn <- makeLearner("classif.ranger",
num.trees = 100,                         ## number of trees DEFAULT: 500
mtry = round(sqrt(ncol(modDat)-1)),      ## someone showed me to declare mtry this way
num.threads = parallel::detectCores()*2, ## CAUTION HERE: how many threads does your machine have?
importance = "impurity",                 ## collect var importance data
predict.type = "prob")                   ## model will generate prob. and multi-class
## Defines the validation method
resp <- makeResampleDesc("RepCV",     ## repeated cross fold
folds = 5,   ## k-folds 5 or 10 as default.  Ideally all folds should be equal size.
reps  = 3)   ## note this will mean 5 x 3 = 50 iterations through the data
## note: 5 fold 3 repeats is a little low.  I would prefer 10 x 10 but that takes additional time...
## Execute cross validation
cv <- mlr::resample(learner = lrn,
task = tsk,
resampling = resp)
saveRDS(cv, file = paste(outDir, "cv_results.rds", sep = "/"))
## Defines the validation method
resp <- makeResampleDesc("RepCV",     ## repeated cross fold
folds = 5,   ## k-folds 5 or 10 as default.  Ideally all folds should be equal size.
reps  = 3)   ## note this will mean 5 x 3 = 50 iterations through the data
## Execute cross validation
cv <- mlr::resample(learner = lrn,
task = tsk,
resampling = resp)
## Create task
tsk <- makeClassifTask(data = modDat, target = "SiteSeries")
class(modDat)
if("sf" %in% class(modDat)) {TRUE}
modDat
modDat2 <- modDat %>% as.data.frame()
modDat2
class(modDat2)
## Load the data
modDat <- sf::st_read("e:/workspace/2020/PEM/ALRF_PEMv2/spatialData/SamplePoints_with_rast_values.gpkg",
quiet = TRUE) %>%
dplyr::select(SiteSeries, aspect_025:VerticalDistance_25m) %>%
dplyr::select(-c(Vertical_distance_025:VerticalDistance_25m,   ## remove problematic covariates
overland_flow_025:OverlandFlowDistance_25m))
## Load the data
modDat <- sf::st_read("e:/workspace/2020/PEM/ALRF_PEMv2/spatialData/SamplePoints_with_rast_values.gpkg",
quiet = TRUE) %>%
dplyr::select(SiteSeries, aspect_025:VerticalDistance_25m) %>%
dplyr::select(-c(Vertical_distance_025:VerticalDistance_25m,   ## remove problematic covariates
overland_flow_025:OverlandFlowDistance_25m)) %>%
as.data.frame()
modDat
modDat <- modDat[, -length(modDat)]
modDat
target <- "SiteSeries"
## define output directory
outDir <- "e:/tmp/mlr_5m_200323/"
rseed <- NA
table(modDat[, target])
## use or create a random number seed -- this can be used to repeat results in future.
if (!is.na(rseed)) {
set.seed(rseed)
print(paste("Random number generator seed set to:", rseed))
} else {
rseed <- as.integer(Sys.time())
print(paste("Random number generator seed set to:", rseed))
}
## Create task
tsk <- makeClassifTask(data = modDat, target = "SiteSeries")
is.na(modDat$SiteSeries)
length(is.na(modDat$SiteSeries))
sum(is.na(modDat$SiteSeries))
modDat <- modDat[!is.na(modDat$SiteSeries)]
modDat <- modDat[!is.na(modDat$SiteSeries),]
## Load the data
modDat <- sf::st_read("e:/workspace/2020/PEM/ALRF_PEMv2/spatialData/SamplePoints_with_rast_values.gpkg",
quiet = TRUE) %>%
dplyr::select(SiteSeries, aspect_025:VerticalDistance_25m) %>%
dplyr::select(-c(Vertical_distance_025:VerticalDistance_25m,   ## remove problematic covariates
overland_flow_025:OverlandFlowDistance_25m)) %>%
as.data.frame()
modDat <- modDat[, -length(modDat)]
modDat <- modDat[!is.na(modDat$SiteSeries),]
target <- "SiteSeries"
## define output directory
outDir <- "e:/tmp/mlr_5m_200323/"
rseed <- NA
table(modDat[, target])
## use or create a random number seed -- this can be used to repeat results in future.
if (!is.na(rseed)) {
set.seed(rseed)
print(paste("Random number generator seed set to:", rseed))
} else {
rseed <- as.integer(Sys.time())
print(paste("Random number generator seed set to:", rseed))
}
## Create task
tsk <- makeClassifTask(data = modDat, target = "SiteSeries")
## Define Learner
lrn <- makeLearner("classif.ranger",
num.trees = 100,                         ## number of trees DEFAULT: 500
mtry = round(sqrt(ncol(modDat)-1)),      ## someone showed me to declare mtry this way
num.threads = parallel::detectCores()*2, ## CAUTION HERE: how many threads does your machine have?
importance = "impurity",                 ## collect var importance data
predict.type = "prob")                   ## model will generate prob. and multi-class
## Defines the validation method
resp <- makeResampleDesc("RepCV",     ## repeated cross fold
folds = 5,   ## k-folds 5 or 10 as default.  Ideally all folds should be equal size.
reps  = 3)   ## note this will mean 5 x 3 = 50 iterations through the data
## note: 5 fold 3 repeats is a little low.  I would prefer 10 x 10 but that takes additional time...
## Execute cross validation
cv <- mlr::resample(learner = lrn,
task = tsk,
resampling = resp)
saveRDS(cv, file = paste(outDir, "cv_results.rds", sep = "/"))
cf_matrix <- calculateConfusionMatrix(cv$pred,
relative = TRUE,
sums = TRUE)
knitr::kable(cf_matrix$result)
knitr::kable(round(cf_matrix$relative.row, 2))
mod <- train(lrn, tsk)
var_imp <- as.data.frame(mod$learner.model$variable.importance) %>%
rownames_to_column()
names(var_imp) <- c("name", "VaribleImportance")
knitr::kable(var_imp %>% arrange(desc(VaribleImportance)) %>% head(., 20))
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
#
# create("PEMWorkFlow")
setwd("e:/workspace/2020/PEM")
?stop
iter <- 12
try(if(iter > 10) stop("too many iterations"))
tst1 <- function(...) stop("dummy error")
try(tst1(1:10, long, calling, expression))
tst2 <- function(...) stop("dummy error", call. = FALSE)
try(tst2(1:10, longcalling, expression, but.not.seen.in.Error))
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
## Install Package
setwd("..")
install("pemGenertaR")
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
?readRDS()
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
??gdalUtils::mosaic_rasters
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
rsf
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
?parse
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
make_lines <- function(GPSPoints, Transects, method = "pts2lines", sortby = "none", tBuffer = 20, PROJ = 3005) {
if (method == "pts2lines") {
## Transects
planT <- Transects %>%
dplyr::mutate(TID = row_number()) %>%
# rename(TID = id)  %>% ## rename the id to not conflict with the GPS id field
sf::st_buffer(.,tBuffer) %>% dplyr::select(TID)
## Transform data to PROJ
planT <- planT %>% sf::st_transform(PROJ)
GPSPoints <- GPSPoints %>% sf::st_transform(PROJ)
## Spatial join attributes
GPSPoints <- st_join(GPSPoints, planT)
## TESTING
# PROJ <- 26910
# GPSPoints <- gpsData #%>% dplyr::select(name, time)
## f(n) start
## ADD TRANSECT ID -- and the arrange TID, time
## Sort Data ---------
if (sortby != "none") {
# sortby <- "name"
sortField <- eval(parse(text = paste0("GPSPoints$", sortby)))
GPSPoints <- GPSPoints[order(sortField),]
}
GPSPoints <- GPSPoints %>%
rowid_to_column("ID") # ID is needed table manipulation below
## convert GPSPoints to a table for manipulation
GPSPoints <- cbind(GPSPoints, sf::st_coordinates(GPSPoints)) %>%
st_zm %>% as.data.frame()
## this solves issue where geom is named 'geometry' other times 'geom'
if("geom" %in% names(GPSPoints)) {
GPSPoints <- GPSPoints %>%  dplyr::rename(geometry = geom)}
## Define the Line Start and End Coordinates
## Add XY coordinates as
lines <- GPSPoints %>%
dplyr::mutate(Xend = lead(X),
Yend = lead(Y)) %>%  # collect the coordinates of the next point
dplyr::filter(!is.na(Yend)) #%>% # drops the last row (start point with no end)
# dplyr::select(-geometry)
## Use data.table with sf to create the line geometry
dt <- data.table::as.data.table(lines)
sf <- dt[,
{
geometry <- sf::st_linestring(x = matrix(c(X, Xend, Y, Yend), ncol = 2))
geometry <- sf::st_sfc(geometry)
geometry <- sf::st_sf(geometry = geometry)
}
, by = ID
]
## Replace the geometry
lines$geometry <- sf$geometry
## Declare as a simple feature
lines <- st_sf(lines)
st_crs(lines) <- PROJ
## Need to remove excess lines -- currently there are lines that run between the plots
lines$within <- as.logical(st_within(lines, planT))
lines <- lines[!is.na(lines$within == TRUE),]  ## removes lines not contained in Transect area
## There are a few invalid geometries
lines$valid <- as.logical(st_is_valid(lines))
# lines <- lines[lines$valid == TRUE,]  ## removes lines not contained in Transect area
# lines <- lines %>% dplyr::select(TID, id, name, time, SiteSeries:Confidence)
return(lines)
} else {
## Begin transect method ----------------------------------------------------
## ADD MC's code here
if (method == "tracklog") {
print("Not built yet")
print("Copy in MC's code")
}
}
}
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
source('E:/workspace/2020/PEM/SetupMaintenance_PEMgeneratr.R')
library(pemgeneratr)
?predict_landscape
